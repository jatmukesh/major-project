{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Prescription Medicine Recognition\n",
    "\n",
    "This notebook implements a TensorFlow-based pipeline for recognizing medicine names from handwritten prescriptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 05:31:41.994547: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.20.0\n"
     ]
    }
   ],
   "source": [
    "# Cell: Imports and Environment Setup\n",
    "import os\n",
    "import json\n",
    "import pathlib\n",
    "import string\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical GPUs: 1, Logical GPUs: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1761024706.581381    9833 gpu_device.cc:2020] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5563 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    }
   ],
   "source": [
    "# Cell: GPU Configuration\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(f\"Physical GPUs: {len(gpus)}, Logical GPUs: {len(logical_gpus)}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print('No GPU detected. Training will fall back to CPU.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data root: /home/mukesh_jat/test/major-project/dataset\n",
      "Training labels: dataset/Training/training_labels.csv\n",
      "Validation labels: dataset/Validation/validation_labels.csv\n",
      "Testing labels: dataset/Testing/testing_labels.csv\n"
     ]
    }
   ],
   "source": [
    "# Cell: Configuration Parameters\n",
    "DATA_ROOT = pathlib.Path('dataset')  # Root directory containing Training/Validation/Testing\n",
    "TRAIN_DIR = DATA_ROOT / 'Training'\n",
    "VAL_DIR = DATA_ROOT / 'Validation'\n",
    "TEST_DIR = DATA_ROOT / 'Testing'\n",
    "\n",
    "TRAIN_IMAGES_DIR = TRAIN_DIR / 'training_words'\n",
    "VAL_IMAGES_DIR = VAL_DIR / 'validation_words'\n",
    "TEST_IMAGES_DIR = TEST_DIR / 'testing_words'\n",
    "\n",
    "TRAIN_LABELS_FILE = TRAIN_DIR / 'training_labels.csv'\n",
    "VAL_LABELS_FILE = VAL_DIR / 'validation_labels.csv'\n",
    "TEST_LABELS_FILE = TEST_DIR / 'testing_labels.csv'\n",
    "\n",
    "IMAGE_COLUMN = 'IMAGE'  # column containing the image filename\n",
    "LABEL_COLUMN = 'MEDICINE_NAME'  # supervised target column; adjust if you want GENERIC_NAME instead\n",
    "\n",
    "OUTPUT_DIR = pathlib.Path('artifacts')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 512\n",
    "BATCH_SIZE = 16\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "MAX_LABEL_LENGTH = 64\n",
    "\n",
    "print(f'Data root: {DATA_ROOT.resolve()}')\n",
    "print(f'Training labels: {TRAIN_LABELS_FILE}')\n",
    "print(f'Validation labels: {VAL_LABELS_FILE}')\n",
    "print(f'Testing labels: {TEST_LABELS_FILE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Placeholder image already exists at /home/mukesh_jat/test/major-project/placeholder.png\n"
     ]
    }
   ],
   "source": [
    "# Cell: Placeholder Asset Creation\n",
    "placeholder_path = pathlib.Path('placeholder.png')\n",
    "if not placeholder_path.exists():\n",
    "    placeholder_image = Image.new('L', (IMG_WIDTH, IMG_HEIGHT), color=255)\n",
    "    placeholder_image.save(placeholder_path)\n",
    "    print(f'Created placeholder image at {placeholder_path.resolve()}')\n",
    "else:\n",
    "    print(f'Placeholder image already exists at {placeholder_path.resolve()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size: 69\n"
     ]
    }
   ],
   "source": [
    "# Cell: Character Vocabulary\n",
    "# Build vocabulary from medical lexicon or dataset labels\n",
    "DEFAULT_CHARSET = string.ascii_lowercase + string.ascii_uppercase + string.digits + ' -./()'\n",
    "\n",
    "def build_vocabulary(labels: List[str], extra_tokens: str = '') -> Tuple[Dict[str, int], Dict[int, str], int, int]:\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "      char_to_num: maps each visible character to [0..N-1]\n",
    "      num_to_char: inverse map\n",
    "      BLANK_INDEX: index reserved for CTC blank (= N)\n",
    "      VOCAB_SIZE: N + 1 (includes the CTC blank at the end)\n",
    "    \"\"\"\n",
    "    characters = sorted(set(''.join(labels)) | set(DEFAULT_CHARSET) | set(extra_tokens))\n",
    "    char_to_num = {ch: i for i, ch in enumerate(characters)}      # 0..N-1\n",
    "    num_to_char = {i: ch for ch, i in char_to_num.items()}\n",
    "    BLANK_INDEX = len(characters)                                  # last index is blank\n",
    "    VOCAB_SIZE = len(characters) + 1\n",
    "    return char_to_num, num_to_char, BLANK_INDEX, VOCAB_SIZE\n",
    "\n",
    "def load_labels(annotation_file: pathlib.Path) -> List[str]:\n",
    "    if not annotation_file.exists():\n",
    "        print(f\"{annotation_file} not found; returning placeholder labels.\")\n",
    "        return ['Paracetamol', 'Ibuprofen']\n",
    "    df = pd.read_csv(annotation_file)\n",
    "    if LABEL_COLUMN not in df.columns:\n",
    "        raise ValueError(f\"Expected column '{LABEL_COLUMN}' in {annotation_file}, found {list(df.columns)}\")\n",
    "    return df[LABEL_COLUMN].astype(str).tolist()\n",
    "\n",
    "raw_labels = load_labels(TRAIN_LABELS_FILE)\n",
    "CHAR_TO_NUM, NUM_TO_CHAR, BLANK_INDEX, VOCAB_SIZE = build_vocabulary(raw_labels)\n",
    "print(f'Vocabulary size (incl. CTC blank): {VOCAB_SIZE} | CTC blank index: {BLANK_INDEX}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f5cb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Data Loading Utilities\n",
    "def read_image(path: tf.Tensor) -> tf.Tensor:\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.io.decode_png(image, channels=1)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    return image\n",
    "\n",
    "@tf.function\n",
    "def preprocess_image(image: tf.Tensor) -> tf.Tensor:\n",
    "    # Ensure float dtype in [0,1]\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "\n",
    "    # 🔄 Rotate portrait images to landscape if needed\n",
    "    shape = tf.shape(image)\n",
    "    height = tf.cast(shape[0], tf.int32)\n",
    "    width = tf.cast(shape[1], tf.int32)\n",
    "    image = tf.cond(height > width,\n",
    "                    lambda: tf.image.rot90(image, k=1),\n",
    "                    lambda: image)\n",
    "\n",
    "    # ✅ Force a fixed square size for all images\n",
    "    image = tf.image.resize(image, [512, 512])\n",
    "    image.set_shape([512, 512, 1])\n",
    "\n",
    "    # ✨ Optional normalization / enhancements\n",
    "    image = tf.clip_by_value(image, 0.0, 1.0)\n",
    "    image = tf.image.adjust_brightness(image, 0.05)\n",
    "    image = tf.image.adjust_contrast(image, 1.5)\n",
    "    return image\n",
    "\n",
    "@tf.function\n",
    "def augment_image(image: tf.Tensor) -> tf.Tensor:\n",
    "    image = tf.image.random_brightness(image, 0.15)\n",
    "    image = tf.image.random_contrast(image, 0.75, 1.25)\n",
    "    image = tf.image.rot90(image, k=tf.random.uniform([], minval=0, maxval=4, dtype=tf.int32))\n",
    "    return image\n",
    "\n",
    "def encode_label_py(label: str) -> np.ndarray:\n",
    "    # Map visible characters to [0..N-1]; CTC blank is not used in labels\n",
    "    encoded = [CHAR_TO_NUM.get(ch, CHAR_TO_NUM.get(' ', 0)) for ch in label.strip()]\n",
    "    # Truncate to MAX_LABEL_LENGTH\n",
    "    encoded = encoded[:MAX_LABEL_LENGTH]\n",
    "    # Pad the rest with -1 (required by keras.backend.ctc_batch_cost)\n",
    "    pad_len = MAX_LABEL_LENGTH - len(encoded)\n",
    "    if pad_len > 0:\n",
    "        encoded = encoded + [-1] * pad_len\n",
    "    return np.array(encoded, dtype=np.int32)\n",
    "\n",
    "\n",
    "@tf.function\n",
    "def prepare_example(path: tf.Tensor, label: tf.Tensor, training: bool = False):\n",
    "    image = read_image(path)\n",
    "    image = preprocess_image(image)\n",
    "    if training:\n",
    "        image = augment_image(image)\n",
    "    label_encoded = tf.numpy_function(func=lambda l: encode_label_py(l.decode('utf-8')), inp=[label], Tout=tf.int32)\n",
    "    label_encoded.set_shape([MAX_LABEL_LENGTH])\n",
    "    return image, label_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da7d4625",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3fd8efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Dataset Pipeline\n",
    "def create_dataset(annotation_file: pathlib.Path, images_dir: pathlib.Path, training: bool = False) -> tf.data.Dataset:\n",
    "    if not annotation_file.exists() or not images_dir.exists():\n",
    "        print(f\"Either {annotation_file} or {images_dir} is missing. Using placeholder samples.\")\n",
    "        dummy_paths = tf.constant([str(pathlib.Path('placeholder.png').resolve())] * len(raw_labels))\n",
    "        dummy_labels = tf.constant(raw_labels)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((dummy_paths, dummy_labels))\n",
    "    else:\n",
    "        df = pd.read_csv(annotation_file)\n",
    "        if IMAGE_COLUMN not in df.columns:\n",
    "            raise ValueError(f\"Expected column '{IMAGE_COLUMN}' in {annotation_file}, found {list(df.columns)}\")\n",
    "        if LABEL_COLUMN not in df.columns:\n",
    "            raise ValueError(f\"Expected column '{LABEL_COLUMN}' in {annotation_file}, found {list(df.columns)}\")\n",
    "        paths = df[IMAGE_COLUMN].apply(lambda p: str((images_dir / p).resolve())).tolist()\n",
    "        labels = df[LABEL_COLUMN].astype(str).tolist()\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "\n",
    "    dataset = dataset.map(lambda p, l: prepare_example(p, l, training), num_parallel_calls=AUTOTUNE)\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_ds = create_dataset(TRAIN_LABELS_FILE, TRAIN_IMAGES_DIR, training=True)\n",
    "val_ds = create_dataset(VAL_LABELS_FILE, VAL_IMAGES_DIR, training=False)\n",
    "test_ds = create_dataset(TEST_LABELS_FILE, TEST_IMAGES_DIR, training=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd034214",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"crnn_model\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"crnn_model\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ image_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)    │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │       <span style=\"color: #00af00; text-decoration-color: #00af00\">295,168</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,180,160</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ permute (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Permute</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">31</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15872</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,015,872</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │       <span style=\"color: #00af00; text-decoration-color: #00af00\">657,408</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,574,912</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">127</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">69</span>)        │        <span style=\"color: #00af00; text-decoration-color: #00af00\">35,397</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ image_input (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m1\u001b[0m)    │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m512\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │           \u001b[38;5;34m640\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m64\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m256\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m)  │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │       \u001b[38;5;34m295,168\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)  │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m256\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │     \u001b[38;5;34m1,180,160\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m128\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │     \u001b[38;5;34m1,049,088\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ permute (\u001b[38;5;33mPermute\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m31\u001b[0m, \u001b[38;5;34m512\u001b[0m)   │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m15872\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │     \u001b[38;5;34m1,015,872\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │       \u001b[38;5;34m657,408\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m512\u001b[0m)       │     \u001b[38;5;34m1,574,912\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_output (\u001b[38;5;33mDense\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m127\u001b[0m, \u001b[38;5;34m69\u001b[0m)        │        \u001b[38;5;34m35,397\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,887,621</span> (22.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m5,887,621\u001b[0m (22.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,885,061</span> (22.45 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,885,061\u001b[0m (22.45 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,560</span> (10.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,560\u001b[0m (10.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ✅ Fixed CRNN Model Architecture for 512×512 Images\n",
    "def build_crnn_model(img_width: int, img_height: int, vocab_size: int) -> keras.Model:\n",
    "    # Input shape updated for 512×512 images\n",
    "    input_img = layers.Input(shape=(img_height, img_width, 1), name='image_input')\n",
    "\n",
    "    # --- Convolutional feature extractor ---\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(input_img)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 1))(x)\n",
    "\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 1))(x)\n",
    "\n",
    "    x = layers.Conv2D(512, (2, 2), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # --- Reshape feature map for sequence modeling ---\n",
    "    x = layers.Permute((2, 1, 3))(x)                # (batch, width, height, channels)\n",
    "    x = layers.TimeDistributed(layers.Flatten())(x) # (batch, width, height*channels)\n",
    "\n",
    "    # --- Recurrent layers ---\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(256, return_sequences=True))(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(256, return_sequences=True))(x)\n",
    "\n",
    "    # --- Output layer ---\n",
    "    output = layers.Dense(vocab_size, activation='softmax', name='dense_output')(x)\n",
    "\n",
    "    model = keras.Model(inputs=input_img, outputs=output, name='crnn_model')\n",
    "    return model\n",
    "\n",
    "\n",
    "# ✅ Build and summarize the model\n",
    "IMG_HEIGHT = 512\n",
    "IMG_WIDTH = 512\n",
    "\n",
    "crnn_model = build_crnn_model(IMG_WIDTH, IMG_HEIGHT, VOCAB_SIZE)\n",
    "crnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e576925",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ✅ CTC Loss and Model Wrapper\n",
    "class CTCLayer(layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = keras.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype='int64')\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype='int64')\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype='int64')\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype='int64')\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype='int64')\n",
    "\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(tf.reduce_mean(loss))\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "def build_ctc_model(base_model: keras.Model) -> keras.Model:\n",
    "    labels = layers.Input(name='label', shape=(MAX_LABEL_LENGTH,), dtype='int32')\n",
    "    y_pred = base_model.output\n",
    "    output = CTCLayer(name='ctc_loss')(labels, y_pred)\n",
    "    ctc_model = keras.Model(inputs=[base_model.input, labels], outputs=output)\n",
    "    return ctc_model\n",
    "\n",
    "\n",
    "ctc_model = build_ctc_model(crnn_model)\n",
    "ctc_model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55f79ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ TensorFlow successfully executed a matmul on: /job:localhost/replica:0/task:0/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Shows which device is being used for ops\n",
    "with tf.device('/device:GPU:0'):\n",
    "    a = tf.random.uniform((1000, 1000))\n",
    "    b = tf.random.uniform((1000, 1000))\n",
    "    c = tf.matmul(a, b)\n",
    "print(\"✅ TensorFlow successfully executed a matmul on:\", c.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "862ee15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[27 47 62 57 60 43 54  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 05:31:51.821867: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "for img, lbl in train_ds.take(1):\n",
    "    lbl_np = lbl.numpy()\n",
    "    print(lbl_np[0])  # check one label sequence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb3eb3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "373eb1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom training step defined. Prefer using ctc_model.fit with tf.data pipelines for full training.\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-21 05:32:04.098867: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:473] Loaded cuDNN version 91400\n",
      "2025-10-21 05:32:17.788656: W tensorflow/core/framework/op_kernel.cc:1855] OP_REQUIRES failed at ctc_loss_op.cc:216 : INVALID_ARGUMENT: Saw a non-null label (index >= num_classes - 1) following a null label, batch: 0 num_classes: 69 labels: 19,57,56,43,68,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 labels seen so far: 19,57,56,43\n",
      "2025-10-21 05:32:17.789984: I tensorflow/core/framework/local_rendezvous.cc:407] Local rendezvous is aborting with status: INVALID_ARGUMENT: Saw a non-null label (index >= num_classes - 1) following a null label, batch: 0 num_classes: 69 labels: 19,57,56,43,68,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 labels seen so far: 19,57,56,43\n",
      "\t [[{{function_node __inference_one_step_on_data_13709}}{{node functional_1/ctc_loss_1/CTCLoss}}]]\n",
      "2025-10-21 05:32:17.790019: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 12849090472934268899\n",
      "2025-10-21 05:32:17.790030: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 6286526720689676706\n",
      "2025-10-21 05:32:17.790461: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous recv item cancelled. Key hash: 11042545795815461920\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node functional_1/ctc_loss_1/CTCLoss defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 758, in start\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 701, in shell_main\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 469, in dispatch_shell\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 379, in execute_request\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 899, in execute_request\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 471, in do_execute\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 632, in run_cell\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n\n  File \"/tmp/ipykernel_9833/1367970404.py\", line 18, in <module>\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 58, in train_step\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 941, in __call__\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/ops/operation.py\", line 59, in __call__\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/models/functional.py\", line 183, in call\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/ops/function.py\", line 206, in _run_through_graph\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/models/functional.py\", line 644, in call\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 941, in __call__\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/ops/operation.py\", line 59, in __call__\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/tmp/ipykernel_9833/2846957595.py\", line 15, in call\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/legacy/backend.py\", line 666, in ctc_batch_cost\n\nDetected at node functional_1/ctc_loss_1/CTCLoss defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 758, in start\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 701, in shell_main\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 469, in dispatch_shell\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 379, in execute_request\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 899, in execute_request\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 471, in do_execute\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 632, in run_cell\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n\n  File \"/tmp/ipykernel_9833/1367970404.py\", line 18, in <module>\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 58, in train_step\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 941, in __call__\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/ops/operation.py\", line 59, in __call__\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/models/functional.py\", line 183, in call\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/ops/function.py\", line 206, in _run_through_graph\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/models/functional.py\", line 644, in call\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 941, in __call__\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/ops/operation.py\", line 59, in __call__\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/tmp/ipykernel_9833/2846957595.py\", line 15, in call\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/legacy/backend.py\", line 666, in ctc_batch_cost\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Saw a non-null label (index >= num_classes - 1) following a null label, batch: 0 num_classes: 69 labels: 19,57,56,43,68,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 labels seen so far: 19,57,56,43\n\t [[{{node functional_1/ctc_loss_1/CTCLoss}}]]\n\t [[StatefulPartitionedCall/functional_1/ctc_loss_1/CTCLoss/_96]]\n  (1) INVALID_ARGUMENT:  Saw a non-null label (index >= num_classes - 1) following a null label, batch: 0 num_classes: 69 labels: 19,57,56,43,68,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 labels seen so far: 19,57,56,43\n\t [[{{node functional_1/ctc_loss_1/CTCLoss}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_13927]",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mInvalidArgumentError\u001b[39m                      Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     16\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mCustom training step defined. Prefer using ctc_model.fit with tf.data pipelines for full training.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Example usage with Keras fit:\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m history = \u001b[43mctc_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_ds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlbl\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimage_input\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlbl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlbl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_ds\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlbl\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mimage_input\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlbl\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlbl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mEPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py:122\u001b[39m, in \u001b[36mfilter_traceback.<locals>.error_handler\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    119\u001b[39m     filtered_tb = _process_traceback_frames(e.__traceback__)\n\u001b[32m    120\u001b[39m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[32m    121\u001b[39m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e.with_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    124\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/test/.venv/lib/python3.12/site-packages/tensorflow/python/eager/execute.py:53\u001b[39m, in \u001b[36mquick_execute\u001b[39m\u001b[34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[39m\n\u001b[32m     51\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     52\u001b[39m   ctx.ensure_initialized()\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m   tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[32m     54\u001b[39m                                       inputs, attrs, num_outputs)\n\u001b[32m     55\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m core._NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m     56\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mInvalidArgumentError\u001b[39m: Graph execution error:\n\nDetected at node functional_1/ctc_loss_1/CTCLoss defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 758, in start\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 701, in shell_main\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 469, in dispatch_shell\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 379, in execute_request\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 899, in execute_request\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 471, in do_execute\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 632, in run_cell\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n\n  File \"/tmp/ipykernel_9833/1367970404.py\", line 18, in <module>\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 58, in train_step\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 941, in __call__\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/ops/operation.py\", line 59, in __call__\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/models/functional.py\", line 183, in call\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/ops/function.py\", line 206, in _run_through_graph\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/models/functional.py\", line 644, in call\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 941, in __call__\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/ops/operation.py\", line 59, in __call__\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/tmp/ipykernel_9833/2846957595.py\", line 15, in call\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/legacy/backend.py\", line 666, in ctc_batch_cost\n\nDetected at node functional_1/ctc_loss_1/CTCLoss defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 758, in start\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 211, in start\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n\n  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n\n  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 701, in shell_main\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 469, in dispatch_shell\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 379, in execute_request\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 899, in execute_request\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 471, in do_execute\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 632, in run_cell\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3116, in run_cell\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3171, in _run_cell\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3394, in run_cell_async\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3639, in run_ast_nodes\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3699, in run_code\n\n  File \"/tmp/ipykernel_9833/1367970404.py\", line 18, in <module>\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 377, in fit\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 220, in function\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 133, in multi_step_on_iterator\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 114, in one_step_on_data\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/backend/tensorflow/trainer.py\", line 58, in train_step\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 941, in __call__\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/ops/operation.py\", line 59, in __call__\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/models/functional.py\", line 183, in call\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/ops/function.py\", line 206, in _run_through_graph\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/models/functional.py\", line 644, in call\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/layers/layer.py\", line 941, in __call__\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/ops/operation.py\", line 59, in __call__\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/utils/traceback_utils.py\", line 156, in error_handler\n\n  File \"/tmp/ipykernel_9833/2846957595.py\", line 15, in call\n\n  File \"/home/mukesh_jat/test/.venv/lib/python3.12/site-packages/keras/src/legacy/backend.py\", line 666, in ctc_batch_cost\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Saw a non-null label (index >= num_classes - 1) following a null label, batch: 0 num_classes: 69 labels: 19,57,56,43,68,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 labels seen so far: 19,57,56,43\n\t [[{{node functional_1/ctc_loss_1/CTCLoss}}]]\n\t [[StatefulPartitionedCall/functional_1/ctc_loss_1/CTCLoss/_96]]\n  (1) INVALID_ARGUMENT:  Saw a non-null label (index >= num_classes - 1) following a null label, batch: 0 num_classes: 69 labels: 19,57,56,43,68,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0 labels seen so far: 19,57,56,43\n\t [[{{node functional_1/ctc_loss_1/CTCLoss}}]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_multi_step_on_iterator_13927]"
     ]
    }
   ],
   "source": [
    "# Cell: Training Loop\n",
    "EPOCHS = 50\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = crnn_model(images, training=True)\n",
    "        ctc_layer = CTCLayer()\n",
    "        _ = ctc_layer(labels, logits)\n",
    "        loss = tf.add_n(ctc_layer.losses) if ctc_layer.losses else 0.0\n",
    "    gradients = tape.gradient(loss, crnn_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, crnn_model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "print('Custom training step defined. Prefer using ctc_model.fit with tf.data pipelines for full training.')\n",
    "# Example usage with Keras fit:\n",
    "history = ctc_model.fit(\n",
    "    train_ds.map(lambda img, lbl: ({'image_input': img, 'label': lbl}, lbl)),\n",
    "    validation_data=val_ds.map(lambda img, lbl: ({'image_input': img, 'label': lbl}, lbl)),\n",
    "    epochs=EPOCHS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Decoding Utilities\n",
    "@tf.function\n",
    "def greedy_decode(pred):\n",
    "    return tf.math.argmax(pred, axis=-1, output_type=tf.int32)\n",
    "\n",
    "\n",
    "def decode_batch_predictions(pred):\n",
    "    results = []\n",
    "    for text in pred:\n",
    "        text = tf.gather(text, tf.where(tf.not_equal(text, 0)))\n",
    "        text = tf.squeeze(text, axis=-1)\n",
    "        chars = [NUM_TO_CHAR.get(int(char), '') for char in text.numpy()]\n",
    "        results.append(''.join(chars))\n",
    "    return results\n",
    "\n",
    "\n",
    "def recognize_medicines(model: keras.Model, dataset: tf.data.Dataset) -> List[List[str]]:\n",
    "    medicines = []\n",
    "    for batch_images, _ in dataset:\n",
    "        preds = model.predict(batch_images)\n",
    "        decoded = decode_batch_predictions(greedy_decode(preds))\n",
    "        medicines.append(decoded)\n",
    "    return medicines\n",
    "\n",
    "print('Decoding utilities ready.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Inference Example\n",
    "def run_inference_example(model: keras.Model, sample_paths: List[str]):\n",
    "    for path in sample_paths:\n",
    "        path_obj = pathlib.Path(path)\n",
    "        if not path_obj.exists():\n",
    "            print(f'Sample {path} not found. Skipping.')\n",
    "            continue\n",
    "        image = tf.io.read_file(str(path_obj))\n",
    "        image = tf.io.decode_png(image, channels=1)\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        image = preprocess_image(image)\n",
    "        image = tf.expand_dims(image, axis=0)\n",
    "        preds = model.predict(image)\n",
    "        decoded = decode_batch_predictions(greedy_decode(preds))\n",
    "        print(f'{path}: {decoded[0]}')\n",
    "\n",
    "print(\"Call `run_inference_example(crnn_model, ['path/to/image.png'])` after training.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Replace placeholder dataset paths with actual annotated prescription data.\n",
    "2. Ensure labels are properly encoded and aligned with the vocabulary.\n",
    "3. Train the model using `ctc_model.fit`.\n",
    "4. Integrate a medicine lexicon for post-processing corrections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Paths\n",
    "\n",
    "The training pipeline expects the dataset to be organized with the following directories relative to the project root:\n",
    "\n",
    "- Training images: `dataset/Training/training_words`\n",
    "- Validation images: `dataset/Validation/validation_words`\n",
    "- Testing images: `dataset/Testing/testing_words`\n",
    "\n",
    "CSV annotation files with the medicine labels are expected at:\n",
    "\n",
    "- Training labels: `dataset/Training/training_labels.csv`\n",
    "- Validation labels: `dataset/Validation/validation_labels.csv`\n",
    "- Testing labels: `dataset/Testing/testing_labels.csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "Fine-tune the CRNN directly from this notebook once the dataset folders are populated at:\n",
    "\n",
    "- `dataset/Training/training_words` with labels in `dataset/Training/training_labels.csv`\n",
    "- `dataset/Validation/validation_words` with labels in `dataset/Validation/validation_labels.csv`\n",
    "- `dataset/Testing/testing_words` with labels in `dataset/Testing/testing_labels.csv`\n",
    "\n",
    "The code below prepares remapped datasets, configures checkpoints and TensorBoard logging under `artifacts/`, and runs `ctc_model.fit`. Adjust the hyperparameters as needed for your hardware and data volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting Training\n",
    "\n",
    "If `ctc_model.fit` fails or exits early, walk through these checks before rerunning training:\n",
    "\n",
    "1. **Verify dataset paths** – confirm the `dataset/Training`, `dataset/Validation`, and `dataset/Testing` folders exist and contain the expected `*_words` subdirectories and CSV files. The helper cell below will print counts if everything is wired correctly.\n",
    "2. **Inspect CSV columns** – the annotation files must include both the `IMAGE` filename column and the `MEDICINE_NAME` label column. Any missing or misspelled header will raise a ValueError when building the datasets.\n",
    "3. **Spot-check a batch** – TensorFlow will fall back to the placeholder samples if directories are empty or paths are wrong. Review the sanity-check output and confirm you see real image paths, not `placeholder.png`.\n",
    "4. **Watch system resources** – large images or high batch sizes may exhaust GPU/CPU RAM. Reduce `BATCH_SIZE`, close other GPU jobs, or run on a machine with more memory if you observe OOM errors.\n",
    "5. **Confirm TensorFlow availability** – ensure the environment has TensorFlow installed with GPU support if desired (e.g., `pip install tensorflow==2.12.*` or `tensorflow-gpu`). Restart the kernel after installation.\n",
    "6. **Resume from checkpoints** – if training stops mid-way, reload the best checkpoint by calling `crnn_model.load_weights('artifacts/checkpoints/<file>.keras')` before restarting to avoid losing progress.\n",
    "\n",
    "Once these checks pass, rerun the callback configuration and the training cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell: Dataset Sanity Checks\n",
    "SUPPORTED_IMAGE_EXTS = ('.png', '.jpg', '.jpeg', '.bmp')\n",
    "\n",
    "def inspect_split(images_dir, labels_file, split_name):\n",
    "    print(f'[{split_name}]')\n",
    "    if not images_dir.exists():\n",
    "        print(f'  ✗ Images directory missing: {images_dir}')\n",
    "    else:\n",
    "        image_files = [p for p in images_dir.iterdir() if p.suffix.lower() in SUPPORTED_IMAGE_EXTS]\n",
    "        sample_files = sorted([p.name for p in image_files[:3]])\n",
    "        print(f'  ✓ Images directory found ({len(image_files)} files with supported extensions)')\n",
    "        if sample_files:\n",
    "            print('  Sample image files:', ', '.join(sample_files))\n",
    "        else:\n",
    "            print('  ⚠️ No files detected with extensions', SUPPORTED_IMAGE_EXTS)\n",
    "    if not labels_file.exists():\n",
    "        print(f'  ✗ Labels CSV missing: {labels_file}')\n",
    "        return\n",
    "    df = pd.read_csv(labels_file)\n",
    "    print(f'  ✓ Labels CSV found with {len(df)} rows and columns: {list(df.columns)}')\n",
    "    missing_cols = [col for col in [IMAGE_COLUMN, LABEL_COLUMN] if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f'  ✗ Missing expected columns: {missing_cols}')\n",
    "    else:\n",
    "        preview = df[[IMAGE_COLUMN, LABEL_COLUMN]].head(3)\n",
    "        print('  Preview:')\n",
    "        for _, row in preview.iterrows():\n",
    "            print(f\"    - {row[IMAGE_COLUMN]} -> {row[LABEL_COLUMN]}\")\n",
    "\n",
    "inspect_split(TRAIN_IMAGES_DIR, TRAIN_LABELS_FILE, 'Training split')\n",
    "inspect_split(VAL_IMAGES_DIR, VAL_LABELS_FILE, 'Validation split')\n",
    "inspect_split(TEST_IMAGES_DIR, TEST_LABELS_FILE, 'Test split')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = OUTPUT_DIR / 'checkpoints'\n",
    "tensorboard_log_dir = OUTPUT_DIR / 'logs'\n",
    "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "tensorboard_log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_inputs = train_ds.map(lambda img, lbl: ({'image_input': img, 'label': lbl}, lbl))\n",
    "val_inputs = val_ds.map(lambda img, lbl: ({'image_input': img, 'label': lbl}, lbl))\n",
    "test_inputs = test_ds.map(lambda img, lbl: ({'image_input': img, 'label': lbl}, lbl))\n",
    "\n",
    "print(f'Checkpoints directory: {checkpoint_dir.resolve()}')\n",
    "print(f'TensorBoard logs directory: {tensorboard_log_dir.resolve()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=str(checkpoint_dir / 'crnn_{epoch:02d}.keras'),\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "    ),\n",
    "    keras.callbacks.TensorBoard(log_dir=str(tensorboard_log_dir)),\n",
    "]\n",
    "\n",
    "history = ctc_model.fit(\n",
    "    train_inputs,\n",
    "    validation_data=val_inputs,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
