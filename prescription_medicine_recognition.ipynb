{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Prescription Medicine Recognition\n",
    "\n",
    "This notebook implements a TensorFlow-based pipeline for recognizing medicine names from handwritten prescriptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Imports and Environment Setup\n",
    "import os\n",
    "import json\n",
    "import pathlib\n",
    "import string\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: GPU Configuration\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(f\"Physical GPUs: {len(gpus)}, Logical GPUs: {len(logical_gpus)}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print('No GPU detected. Training will fall back to CPU.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Configuration Parameters\n",
    "DATA_ROOT = pathlib.Path('dataset')  # Root directory containing Training/Validation/Testing\n",
    "TRAIN_DIR = DATA_ROOT / 'Training'\n",
    "VAL_DIR = DATA_ROOT / 'Validation'\n",
    "TEST_DIR = DATA_ROOT / 'Testing'\n",
    "\n",
    "TRAIN_IMAGES_DIR = TRAIN_DIR / 'training_words'\n",
    "VAL_IMAGES_DIR = VAL_DIR / 'validation_words'\n",
    "TEST_IMAGES_DIR = TEST_DIR / 'testing_words'\n",
    "\n",
    "TRAIN_LABELS_FILE = TRAIN_DIR / 'training_labels.csv'\n",
    "VAL_LABELS_FILE = VAL_DIR / 'validation_labels.csv'\n",
    "TEST_LABELS_FILE = TEST_DIR / 'testing_labels.csv'\n",
    "\n",
    "IMAGE_COLUMN = 'IMAGE'  # column containing the image filename\n",
    "LABEL_COLUMN = 'MEDICINE_NAME'  # supervised target column; adjust if you want GENERIC_NAME instead\n",
    "\n",
    "OUTPUT_DIR = pathlib.Path('artifacts')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 512\n",
    "BATCH_SIZE = 16\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "MAX_LABEL_LENGTH = 64\n",
    "\n",
    "print(f'Data root: {DATA_ROOT.resolve()}')\n",
    "print(f'Training labels: {TRAIN_LABELS_FILE}')\n",
    "print(f'Validation labels: {VAL_LABELS_FILE}')\n",
    "print(f'Testing labels: {TEST_LABELS_FILE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Placeholder Asset Creation\n",
    "placeholder_path = pathlib.Path('placeholder.png')\n",
    "if not placeholder_path.exists():\n",
    "    placeholder_image = Image.new('L', (IMG_WIDTH, IMG_HEIGHT), color=255)\n",
    "    placeholder_image.save(placeholder_path)\n",
    "    print(f'Created placeholder image at {placeholder_path.resolve()}')\n",
    "else:\n",
    "    print(f'Placeholder image already exists at {placeholder_path.resolve()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Character Vocabulary\n",
    "# Build vocabulary from medical lexicon or dataset labels\n",
    "DEFAULT_CHARSET = string.ascii_lowercase + string.ascii_uppercase + string.digits + ' -./()'\n",
    "\n",
    "def build_vocabulary(labels: List[str], extra_tokens: str = '') -> Tuple[Dict[str, int], Dict[int, str]]:\n",
    "    characters = sorted(set(''.join(labels)) | set(DEFAULT_CHARSET) | set(extra_tokens))\n",
    "    char_to_num = {char: idx + 1 for idx, char in enumerate(characters)}\n",
    "    char_to_num['<BLANK>'] = 0\n",
    "    num_to_char = {idx: char for char, idx in char_to_num.items()}\n",
    "    return char_to_num, num_to_char\n",
    "\n",
    "def load_labels(annotation_file: pathlib.Path) -> List[str]:\n",
    "    if not annotation_file.exists():\n",
    "        print(f\"{annotation_file} not found; returning placeholder labels.\")\n",
    "        return ['Paracetamol', 'Ibuprofen']\n",
    "    df = pd.read_csv(annotation_file)\n",
    "    if LABEL_COLUMN not in df.columns:\n",
    "        raise ValueError(f\"Expected column '{LABEL_COLUMN}' in {annotation_file}, found {list(df.columns)}\")\n",
    "    return df[LABEL_COLUMN].astype(str).tolist()\n",
    "\n",
    "raw_labels = load_labels(TRAIN_LABELS_FILE)\n",
    "CHAR_TO_NUM, NUM_TO_CHAR = build_vocabulary(raw_labels)\n",
    "VOCAB_SIZE = len(CHAR_TO_NUM)\n",
    "print(f'Vocabulary size: {VOCAB_SIZE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Data Loading Utilities\n",
    "def read_image(path: tf.Tensor) -> tf.Tensor:\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.io.decode_png(image, channels=1)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    return image\n",
    "\n",
    "@tf.function\n",
    "def preprocess_image(image: tf.Tensor) -> tf.Tensor:\n",
    "    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH], preserve_aspect_ratio=True)\n",
    "    image = tf.image.pad_to_bounding_box(image, 0, 0, IMG_HEIGHT, IMG_WIDTH)\n",
    "    image = tf.image.adjust_brightness(image, 0.05)\n",
    "    image = tf.image.adjust_contrast(image, 1.5)\n",
    "    return image\n",
    "\n",
    "@tf.function\n",
    "def augment_image(image: tf.Tensor) -> tf.Tensor:\n",
    "    image = tf.image.random_brightness(image, 0.15)\n",
    "    image = tf.image.random_contrast(image, 0.75, 1.25)\n",
    "    image = tf.image.rot90(image, k=tf.random.uniform([], minval=0, maxval=4, dtype=tf.int32))\n",
    "    return image\n",
    "\n",
    "def encode_label_py(label: str) -> np.ndarray:\n",
    "    label_chars = list(label)\n",
    "    encoded = [CHAR_TO_NUM.get(ch, CHAR_TO_NUM[' ']) for ch in label_chars]\n",
    "    encoded = encoded[:MAX_LABEL_LENGTH]\n",
    "    padding = [0] * (MAX_LABEL_LENGTH - len(encoded))\n",
    "    return np.array(encoded + padding, dtype=np.int32)\n",
    "\n",
    "@tf.function\n",
    "def prepare_example(path: tf.Tensor, label: tf.Tensor, training: bool = False):\n",
    "    image = read_image(path)\n",
    "    image = preprocess_image(image)\n",
    "    if training:\n",
    "        image = augment_image(image)\n",
    "    label_encoded = tf.numpy_function(func=lambda l: encode_label_py(l.decode('utf-8')), inp=[label], Tout=tf.int32)\n",
    "    label_encoded.set_shape([MAX_LABEL_LENGTH])\n",
    "    return image, label_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Dataset Pipeline\n",
    "def create_dataset(annotation_file: pathlib.Path, images_dir: pathlib.Path, training: bool = False) -> tf.data.Dataset:\n",
    "    if not annotation_file.exists() or not images_dir.exists():\n",
    "        print(f\"Either {annotation_file} or {images_dir} is missing. Using placeholder samples.\")\n",
    "        dummy_paths = tf.constant([str(pathlib.Path('placeholder.png').resolve())] * len(raw_labels))\n",
    "        dummy_labels = tf.constant(raw_labels)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((dummy_paths, dummy_labels))\n",
    "    else:\n",
    "        df = pd.read_csv(annotation_file)\n",
    "        if IMAGE_COLUMN not in df.columns:\n",
    "            raise ValueError(f\"Expected column '{IMAGE_COLUMN}' in {annotation_file}, found {list(df.columns)}\")\n",
    "        if LABEL_COLUMN not in df.columns:\n",
    "            raise ValueError(f\"Expected column '{LABEL_COLUMN}' in {annotation_file}, found {list(df.columns)}\")\n",
    "        paths = df[IMAGE_COLUMN].apply(lambda p: str((images_dir / p).resolve())).tolist()\n",
    "        labels = df[LABEL_COLUMN].astype(str).tolist()\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "\n",
    "    dataset = dataset.map(lambda p, l: prepare_example(p, l, training), num_parallel_calls=AUTOTUNE)\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_ds = create_dataset(TRAIN_LABELS_FILE, TRAIN_IMAGES_DIR, training=True)\n",
    "val_ds = create_dataset(VAL_LABELS_FILE, VAL_IMAGES_DIR, training=False)\n",
    "test_ds = create_dataset(TEST_LABELS_FILE, TEST_IMAGES_DIR, training=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Model Architecture\n",
    "def build_crnn_model(img_width: int, img_height: int, vocab_size: int) -> keras.Model:\n",
    "    input_img = layers.Input(shape=(img_height, img_width, 1), name='image_input')\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(input_img)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 1))(x)\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 1))(x)\n",
    "    x = layers.Conv2D(512, (2, 2), activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    new_shape = (img_width // 4, 512)\n",
    "    x = layers.Reshape(target_shape=new_shape)(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(256, return_sequences=True))(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(256, return_sequences=True))(x)\n",
    "\n",
    "    output = layers.Dense(vocab_size, activation='softmax', name='dense_output')(x)\n",
    "\n",
    "    model = keras.Model(inputs=input_img, outputs=output, name='crnn_model')\n",
    "    return model\n",
    "\n",
    "crnn_model = build_crnn_model(IMG_WIDTH, IMG_HEIGHT, VOCAB_SIZE)\n",
    "crnn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: CTC Loss and Training Step\n",
    "class CTCLayer(layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = keras.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype='int64')\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype='int64')\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype='int64')\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype='int64')\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype='int64')\n",
    "\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(tf.reduce_mean(loss))\n",
    "        return y_pred\n",
    "\n",
    "def build_ctc_model(base_model: keras.Model) -> keras.Model:\n",
    "    labels = layers.Input(name='label', shape=(MAX_LABEL_LENGTH,), dtype='int32')\n",
    "    y_pred = base_model.output\n",
    "    output = CTCLayer(name='ctc_loss')(labels, y_pred)\n",
    "    ctc_model = keras.Model(inputs=[base_model.input, labels], outputs=output)\n",
    "    return ctc_model\n",
    "\n",
    "ctc_model = build_ctc_model(crnn_model)\n",
    "ctc_model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Training Loop\n",
    "EPOCHS = 50\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = crnn_model(images, training=True)\n",
    "        ctc_layer = CTCLayer()\n",
    "        _ = ctc_layer(labels, logits)\n",
    "        loss = tf.add_n(ctc_layer.losses) if ctc_layer.losses else 0.0\n",
    "    gradients = tape.gradient(loss, crnn_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, crnn_model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "print('Custom training step defined. Prefer using ctc_model.fit with tf.data pipelines for full training.')\n",
    "# Example usage with Keras fit:\n",
    "# history = ctc_model.fit(\n",
    "#     train_ds.map(lambda img, lbl: ({'image_input': img, 'label': lbl}, lbl)),\n",
    "#     validation_data=val_ds.map(lambda img, lbl: ({'image_input': img, 'label': lbl}, lbl)),\n",
    "#     epochs=EPOCHS,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Decoding Utilities\n",
    "@tf.function\n",
    "def greedy_decode(pred):\n",
    "    return tf.math.argmax(pred, axis=-1, output_type=tf.int32)\n",
    "\n",
    "\n",
    "def decode_batch_predictions(pred):\n",
    "    results = []\n",
    "    for text in pred:\n",
    "        text = tf.gather(text, tf.where(tf.not_equal(text, 0)))\n",
    "        text = tf.squeeze(text, axis=-1)\n",
    "        chars = [NUM_TO_CHAR.get(int(char), '') for char in text.numpy()]\n",
    "        results.append(''.join(chars))\n",
    "    return results\n",
    "\n",
    "\n",
    "def recognize_medicines(model: keras.Model, dataset: tf.data.Dataset) -> List[List[str]]:\n",
    "    medicines = []\n",
    "    for batch_images, _ in dataset:\n",
    "        preds = model.predict(batch_images)\n",
    "        decoded = decode_batch_predictions(greedy_decode(preds))\n",
    "        medicines.append(decoded)\n",
    "    return medicines\n",
    "\n",
    "print('Decoding utilities ready.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Inference Example\n",
    "def run_inference_example(model: keras.Model, sample_paths: List[str]):\n",
    "    for path in sample_paths:\n",
    "        path_obj = pathlib.Path(path)\n",
    "        if not path_obj.exists():\n",
    "            print(f'Sample {path} not found. Skipping.')\n",
    "            continue\n",
    "        image = tf.io.read_file(str(path_obj))\n",
    "        image = tf.io.decode_png(image, channels=1)\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        image = preprocess_image(image)\n",
    "        image = tf.expand_dims(image, axis=0)\n",
    "        preds = model.predict(image)\n",
    "        decoded = decode_batch_predictions(greedy_decode(preds))\n",
    "        print(f'{path}: {decoded[0]}')\n",
    "\n",
    "print(\"Call `run_inference_example(crnn_model, ['path/to/image.png'])` after training.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Replace placeholder dataset paths with actual annotated prescription data.\n",
    "2. Ensure labels are properly encoded and aligned with the vocabulary.\n",
    "3. Train the model using `ctc_model.fit`.\n",
    "4. Integrate a medicine lexicon for post-processing corrections.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}