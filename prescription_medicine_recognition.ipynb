{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handwritten Prescription Medicine Recognition\n",
    "\n",
    "This notebook implements a TensorFlow-based pipeline for recognizing medicine names from handwritten prescriptions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-20 12:44:53.464510: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# Cell: Imports and Environment Setup\n",
    "import os\n",
    "import json\n",
    "import pathlib\n",
    "import string\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: GPU Configuration\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "        print(f\"Physical GPUs: {len(gpus)}, Logical GPUs: {len(logical_gpus)}\")\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "else:\n",
    "    print('No GPU detected. Training will fall back to CPU.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Configuration Parameters\n",
    "DATA_ROOT = pathlib.Path('dataset')  # Root directory containing Training/Validation/Testing\n",
    "TRAIN_DIR = DATA_ROOT / 'Training'\n",
    "VAL_DIR = DATA_ROOT / 'Validation'\n",
    "TEST_DIR = DATA_ROOT / 'Testing'\n",
    "\n",
    "TRAIN_IMAGES_DIR = TRAIN_DIR / 'training_words'\n",
    "VAL_IMAGES_DIR = VAL_DIR / 'validation_words'\n",
    "TEST_IMAGES_DIR = TEST_DIR / 'testing_words'\n",
    "\n",
    "TRAIN_LABELS_FILE = TRAIN_DIR / 'training_labels.csv'\n",
    "VAL_LABELS_FILE = VAL_DIR / 'validation_labels.csv'\n",
    "TEST_LABELS_FILE = TEST_DIR / 'testing_labels.csv'\n",
    "\n",
    "IMAGE_COLUMN = 'IMAGE'  # column containing the image filename\n",
    "LABEL_COLUMN = 'MEDICINE_NAME'  # supervised target column; adjust if you want GENERIC_NAME instead\n",
    "\n",
    "OUTPUT_DIR = pathlib.Path('artifacts')\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "IMG_HEIGHT = 128\n",
    "IMG_WIDTH = 512\n",
    "BATCH_SIZE = 16\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "MAX_LABEL_LENGTH = 64\n",
    "\n",
    "print(f'Data root: {DATA_ROOT.resolve()}')\n",
    "print(f'Training labels: {TRAIN_LABELS_FILE}')\n",
    "print(f'Validation labels: {VAL_LABELS_FILE}')\n",
    "print(f'Testing labels: {TEST_LABELS_FILE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Placeholder Asset Creation\n",
    "placeholder_path = pathlib.Path('placeholder.png')\n",
    "if not placeholder_path.exists():\n",
    "    placeholder_image = Image.new('L', (IMG_WIDTH, IMG_HEIGHT), color=255)\n",
    "    placeholder_image.save(placeholder_path)\n",
    "    print(f'Created placeholder image at {placeholder_path.resolve()}')\n",
    "else:\n",
    "    print(f'Placeholder image already exists at {placeholder_path.resolve()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Character Vocabulary\n",
    "# Build vocabulary from medical lexicon or dataset labels\n",
    "DEFAULT_CHARSET = string.ascii_lowercase + string.ascii_uppercase + string.digits + ' -./()'\n",
    "\n",
    "def build_vocabulary(labels: List[str], extra_tokens: str = '') -> Tuple[Dict[str, int], Dict[int, str]]:\n",
    "    characters = sorted(set(''.join(labels)) | set(DEFAULT_CHARSET) | set(extra_tokens))\n",
    "    char_to_num = {char: idx + 1 for idx, char in enumerate(characters)}\n",
    "    char_to_num['<BLANK>'] = 0\n",
    "    num_to_char = {idx: char for char, idx in char_to_num.items()}\n",
    "    return char_to_num, num_to_char\n",
    "\n",
    "def load_labels(annotation_file: pathlib.Path) -> List[str]:\n",
    "    if not annotation_file.exists():\n",
    "        print(f\"{annotation_file} not found; returning placeholder labels.\")\n",
    "        return ['Paracetamol', 'Ibuprofen']\n",
    "    df = pd.read_csv(annotation_file)\n",
    "    if LABEL_COLUMN not in df.columns:\n",
    "        raise ValueError(f\"Expected column '{LABEL_COLUMN}' in {annotation_file}, found {list(df.columns)}\")\n",
    "    return df[LABEL_COLUMN].astype(str).tolist()\n",
    "\n",
    "raw_labels = load_labels(TRAIN_LABELS_FILE)\n",
    "CHAR_TO_NUM, NUM_TO_CHAR = build_vocabulary(raw_labels)\n",
    "VOCAB_SIZE = len(CHAR_TO_NUM)\n",
    "print(f'Vocabulary size: {VOCAB_SIZE}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Data Loading Utilities\n",
    "def read_image(path: tf.Tensor) -> tf.Tensor:\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.io.decode_png(image, channels=1)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    return image\n",
    "\n",
    "@tf.function\n",
    "def preprocess_image(image: tf.Tensor) -> tf.Tensor:\n",
    "    image = tf.image.resize(image, [IMG_HEIGHT, IMG_WIDTH], preserve_aspect_ratio=True)\n",
    "    image = tf.image.pad_to_bounding_box(image, 0, 0, IMG_HEIGHT, IMG_WIDTH)\n",
    "    image = tf.image.adjust_brightness(image, 0.05)\n",
    "    image = tf.image.adjust_contrast(image, 1.5)\n",
    "    return image\n",
    "\n",
    "@tf.function\n",
    "def augment_image(image: tf.Tensor) -> tf.Tensor:\n",
    "    image = tf.image.random_brightness(image, 0.15)\n",
    "    image = tf.image.random_contrast(image, 0.75, 1.25)\n",
    "    image = tf.image.rot90(image, k=tf.random.uniform([], minval=0, maxval=4, dtype=tf.int32))\n",
    "    return image\n",
    "\n",
    "def encode_label_py(label: str) -> np.ndarray:\n",
    "    label_chars = list(label)\n",
    "    encoded = [CHAR_TO_NUM.get(ch, CHAR_TO_NUM[' ']) for ch in label_chars]\n",
    "    encoded = encoded[:MAX_LABEL_LENGTH]\n",
    "    padding = [0] * (MAX_LABEL_LENGTH - len(encoded))\n",
    "    return np.array(encoded + padding, dtype=np.int32)\n",
    "\n",
    "@tf.function\n",
    "def prepare_example(path: tf.Tensor, label: tf.Tensor, training: bool = False):\n",
    "    image = read_image(path)\n",
    "    image = preprocess_image(image)\n",
    "    if training:\n",
    "        image = augment_image(image)\n",
    "    label_encoded = tf.numpy_function(func=lambda l: encode_label_py(l.decode('utf-8')), inp=[label], Tout=tf.int32)\n",
    "    label_encoded.set_shape([MAX_LABEL_LENGTH])\n",
    "    return image, label_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Dataset Pipeline\n",
    "def create_dataset(annotation_file: pathlib.Path, images_dir: pathlib.Path, training: bool = False) -> tf.data.Dataset:\n",
    "    if not annotation_file.exists() or not images_dir.exists():\n",
    "        print(f\"Either {annotation_file} or {images_dir} is missing. Using placeholder samples.\")\n",
    "        dummy_paths = tf.constant([str(pathlib.Path('placeholder.png').resolve())] * len(raw_labels))\n",
    "        dummy_labels = tf.constant(raw_labels)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((dummy_paths, dummy_labels))\n",
    "    else:\n",
    "        df = pd.read_csv(annotation_file)\n",
    "        if IMAGE_COLUMN not in df.columns:\n",
    "            raise ValueError(f\"Expected column '{IMAGE_COLUMN}' in {annotation_file}, found {list(df.columns)}\")\n",
    "        if LABEL_COLUMN not in df.columns:\n",
    "            raise ValueError(f\"Expected column '{LABEL_COLUMN}' in {annotation_file}, found {list(df.columns)}\")\n",
    "        paths = df[IMAGE_COLUMN].apply(lambda p: str((images_dir / p).resolve())).tolist()\n",
    "        labels = df[LABEL_COLUMN].astype(str).tolist()\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "\n",
    "    dataset = dataset.map(lambda p, l: prepare_example(p, l, training), num_parallel_calls=AUTOTUNE)\n",
    "    if training:\n",
    "        dataset = dataset.shuffle(2048)\n",
    "    dataset = dataset.batch(BATCH_SIZE).prefetch(AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "train_ds = create_dataset(TRAIN_LABELS_FILE, TRAIN_IMAGES_DIR, training=True)\n",
    "val_ds = create_dataset(VAL_LABELS_FILE, VAL_IMAGES_DIR, training=False)\n",
    "test_ds = create_dataset(TEST_LABELS_FILE, TEST_IMAGES_DIR, training=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Model Architecture\n",
    "def build_crnn_model(img_width: int, img_height: int, vocab_size: int) -> keras.Model:\n",
    "    input_img = layers.Input(shape=(img_height, img_width, 1), name='image_input')\n",
    "    x = layers.Conv2D(64, (3, 3), padding='same', activation='relu')(input_img)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Conv2D(128, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = layers.Conv2D(256, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 1))(x)\n",
    "    x = layers.Conv2D(512, (3, 3), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling2D(pool_size=(2, 1))(x)\n",
    "    x = layers.Conv2D(512, (2, 2), padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    x = layers.Permute((2, 1, 3), name='permute_width_first')(x)\n",
    "    x = layers.Lambda(\n",
    "        lambda t: tf.reshape(t, (tf.shape(t)[0], tf.shape(t)[1], tf.shape(t)[2] * tf.shape(t)[3])),\n",
    "        name='flatten_height_channels',\n",
    "        output_shape=lambda s: (s[1], s[2] * s[3]),\n",
    "    )(x)\n",
    "    x = layers.Dense(64, activation='relu')(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(256, return_sequences=True))(x)\n",
    "    x = layers.Dropout(0.2)(x)\n",
    "    x = layers.Bidirectional(layers.LSTM(256, return_sequences=True))(x)\n",
    "\n",
    "    output = layers.Dense(vocab_size, activation='softmax', name='dense_output')(x)\n",
    "\n",
    "    model = keras.Model(inputs=input_img, outputs=output, name='crnn_model')\n",
    "    return model\n",
    "\n",
    "crnn_model = build_crnn_model(IMG_WIDTH, IMG_HEIGHT, VOCAB_SIZE)\n",
    "crnn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: CTC Loss and Training Step\n",
    "class CTCLayer(layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = keras.backend.ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        batch_len = tf.cast(tf.shape(y_true)[0], dtype='int64')\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype='int64')\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype='int64')\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_len, 1), dtype='int64')\n",
    "        label_length = label_length * tf.ones(shape=(batch_len, 1), dtype='int64')\n",
    "\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(tf.reduce_mean(loss))\n",
    "        return y_pred\n",
    "\n",
    "def build_ctc_model(base_model: keras.Model) -> keras.Model:\n",
    "    labels = layers.Input(name='label', shape=(MAX_LABEL_LENGTH,), dtype='int32')\n",
    "    y_pred = base_model.output\n",
    "    output = CTCLayer(name='ctc_loss')(labels, y_pred)\n",
    "    ctc_model = keras.Model(inputs=[base_model.input, labels], outputs=output)\n",
    "    return ctc_model\n",
    "\n",
    "ctc_model = build_ctc_model(crnn_model)\n",
    "ctc_model.compile(optimizer=keras.optimizers.Adam(learning_rate=1e-4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Training Loop\n",
    "EPOCHS = 50\n",
    "optimizer = keras.optimizers.Adam(learning_rate=1e-4)\n",
    "\n",
    "@tf.function\n",
    "def train_step(images, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "        logits = crnn_model(images, training=True)\n",
    "        ctc_layer = CTCLayer()\n",
    "        _ = ctc_layer(labels, logits)\n",
    "        loss = tf.add_n(ctc_layer.losses) if ctc_layer.losses else 0.0\n",
    "    gradients = tape.gradient(loss, crnn_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, crnn_model.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "print('Custom training step defined. Prefer using ctc_model.fit with tf.data pipelines for full training.')\n",
    "# Example usage with Keras fit:\n",
    "# history = ctc_model.fit(\n",
    "#     train_ds.map(lambda img, lbl: ({'image_input': img, 'label': lbl}, lbl)),\n",
    "#     validation_data=val_ds.map(lambda img, lbl: ({'image_input': img, 'label': lbl}, lbl)),\n",
    "#     epochs=EPOCHS,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Decoding Utilities\n",
    "@tf.function\n",
    "def greedy_decode(pred):\n",
    "    return tf.math.argmax(pred, axis=-1, output_type=tf.int32)\n",
    "\n",
    "\n",
    "def decode_batch_predictions(pred):\n",
    "    results = []\n",
    "    for text in pred:\n",
    "        text = tf.gather(text, tf.where(tf.not_equal(text, 0)))\n",
    "        text = tf.squeeze(text, axis=-1)\n",
    "        chars = [NUM_TO_CHAR.get(int(char), '') for char in text.numpy()]\n",
    "        results.append(''.join(chars))\n",
    "    return results\n",
    "\n",
    "\n",
    "def recognize_medicines(model: keras.Model, dataset: tf.data.Dataset) -> List[List[str]]:\n",
    "    medicines = []\n",
    "    for batch_images, _ in dataset:\n",
    "        preds = model.predict(batch_images)\n",
    "        decoded = decode_batch_predictions(greedy_decode(preds))\n",
    "        medicines.append(decoded)\n",
    "    return medicines\n",
    "\n",
    "print('Decoding utilities ready.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell: Inference Example\n",
    "def run_inference_example(model: keras.Model, sample_paths: List[str]):\n",
    "    for path in sample_paths:\n",
    "        path_obj = pathlib.Path(path)\n",
    "        if not path_obj.exists():\n",
    "            print(f'Sample {path} not found. Skipping.')\n",
    "            continue\n",
    "        image = tf.io.read_file(str(path_obj))\n",
    "        image = tf.io.decode_png(image, channels=1)\n",
    "        image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "        image = preprocess_image(image)\n",
    "        image = tf.expand_dims(image, axis=0)\n",
    "        preds = model.predict(image)\n",
    "        decoded = decode_batch_predictions(greedy_decode(preds))\n",
    "        print(f'{path}: {decoded[0]}')\n",
    "\n",
    "print(\"Call `run_inference_example(crnn_model, ['path/to/image.png'])` after training.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "1. Replace placeholder dataset paths with actual annotated prescription data.\n",
    "2. Ensure labels are properly encoded and aligned with the vocabulary.\n",
    "3. Train the model using `ctc_model.fit`.\n",
    "4. Integrate a medicine lexicon for post-processing corrections.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Paths\n",
    "\n",
    "The training pipeline expects the dataset to be organized with the following directories relative to the project root:\n",
    "\n",
    "- Training images: `dataset/Training/training_words`\n",
    "- Validation images: `dataset/Validation/validation_words`\n",
    "- Testing images: `dataset/Testing/testing_words`\n",
    "\n",
    "CSV annotation files with the medicine labels are expected at:\n",
    "\n",
    "- Training labels: `dataset/Training/training_labels.csv`\n",
    "- Validation labels: `dataset/Validation/validation_labels.csv`\n",
    "- Testing labels: `dataset/Testing/testing_labels.csv`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model\n",
    "\n",
    "Fine-tune the CRNN directly from this notebook once the dataset folders are populated at:\n",
    "\n",
    "- `dataset/Training/training_words` with labels in `dataset/Training/training_labels.csv`\n",
    "- `dataset/Validation/validation_words` with labels in `dataset/Validation/validation_labels.csv`\n",
    "- `dataset/Testing/testing_words` with labels in `dataset/Testing/testing_labels.csv`\n",
    "\n",
    "The code below prepares remapped datasets, configures checkpoints and TensorBoard logging under `artifacts/`, and runs `ctc_model.fit`. Adjust the hyperparameters as needed for your hardware and data volume.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Troubleshooting Training\n",
    "\n",
    "If `ctc_model.fit` fails or exits early, walk through these checks before rerunning training:\n",
    "\n",
    "1. **Verify dataset paths** \u2013 confirm the `dataset/Training`, `dataset/Validation`, and `dataset/Testing` folders exist and contain the expected `*_words` subdirectories and CSV files. The helper cell below will print counts if everything is wired correctly.\n",
    "2. **Inspect CSV columns** \u2013 the annotation files must include both the `IMAGE` filename column and the `MEDICINE_NAME` label column. Any missing or misspelled header will raise a ValueError when building the datasets.\n",
    "3. **Spot-check a batch** \u2013 TensorFlow will fall back to the placeholder samples if directories are empty or paths are wrong. Review the sanity-check output and confirm you see real image paths, not `placeholder.png`.\n",
    "4. **Watch system resources** \u2013 large images or high batch sizes may exhaust GPU/CPU RAM. Reduce `BATCH_SIZE`, close other GPU jobs, or run on a machine with more memory if you observe OOM errors.\n",
    "5. **Confirm TensorFlow availability** \u2013 ensure the environment has TensorFlow installed with GPU support if desired (e.g., `pip install tensorflow==2.12.*` or `tensorflow-gpu`). Restart the kernel after installation.\n",
    "6. **Resume from checkpoints** \u2013 if training stops mid-way, reload the best checkpoint by calling `crnn_model.load_weights('artifacts/checkpoints/<file>.keras')` before restarting to avoid losing progress.\n",
    "\n",
    "Once these checks pass, rerun the callback configuration and the training cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Cell: Dataset Sanity Checks\n",
    "SUPPORTED_IMAGE_EXTS = ('.png', '.jpg', '.jpeg', '.bmp')\n",
    "\n",
    "def inspect_split(images_dir, labels_file, split_name):\n",
    "    print(f'[{split_name}]')\n",
    "    if not images_dir.exists():\n",
    "        print(f'  \u2717 Images directory missing: {images_dir}')\n",
    "    else:\n",
    "        image_files = [p for p in images_dir.iterdir() if p.suffix.lower() in SUPPORTED_IMAGE_EXTS]\n",
    "        sample_files = sorted([p.name for p in image_files[:3]])\n",
    "        print(f'  \u2713 Images directory found ({len(image_files)} files with supported extensions)')\n",
    "        if sample_files:\n",
    "            print('  Sample image files:', ', '.join(sample_files))\n",
    "        else:\n",
    "            print('  \u26a0\ufe0f No files detected with extensions', SUPPORTED_IMAGE_EXTS)\n",
    "    if not labels_file.exists():\n",
    "        print(f'  \u2717 Labels CSV missing: {labels_file}')\n",
    "        return\n",
    "    df = pd.read_csv(labels_file)\n",
    "    print(f'  \u2713 Labels CSV found with {len(df)} rows and columns: {list(df.columns)}')\n",
    "    missing_cols = [col for col in [IMAGE_COLUMN, LABEL_COLUMN] if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f'  \u2717 Missing expected columns: {missing_cols}')\n",
    "    else:\n",
    "        preview = df[[IMAGE_COLUMN, LABEL_COLUMN]].head(3)\n",
    "        print('  Preview:')\n",
    "        for _, row in preview.iterrows():\n",
    "            print(f\"    - {row[IMAGE_COLUMN]} -> {row[LABEL_COLUMN]}\")\n",
    "\n",
    "inspect_split(TRAIN_IMAGES_DIR, TRAIN_LABELS_FILE, 'Training split')\n",
    "inspect_split(VAL_IMAGES_DIR, VAL_LABELS_FILE, 'Validation split')\n",
    "inspect_split(TEST_IMAGES_DIR, TEST_LABELS_FILE, 'Test split')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = OUTPUT_DIR / 'checkpoints'\n",
    "tensorboard_log_dir = OUTPUT_DIR / 'logs'\n",
    "checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "tensorboard_log_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "train_inputs = train_ds.map(lambda img, lbl: ({'image_input': img, 'label': lbl}, lbl))\n",
    "val_inputs = val_ds.map(lambda img, lbl: ({'image_input': img, 'label': lbl}, lbl))\n",
    "test_inputs = test_ds.map(lambda img, lbl: ({'image_input': img, 'label': lbl}, lbl))\n",
    "\n",
    "print(f'Checkpoints directory: {checkpoint_dir.resolve()}')\n",
    "print(f'TensorBoard logs directory: {tensorboard_log_dir.resolve()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath=str(checkpoint_dir / 'crnn_{epoch:02d}.keras'),\n",
    "        monitor='val_loss',\n",
    "        mode='min',\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=1e-6,\n",
    "    ),\n",
    "    keras.callbacks.TensorBoard(log_dir=str(tensorboard_log_dir)),\n",
    "]\n",
    "\n",
    "history = ctc_model.fit(\n",
    "    train_inputs,\n",
    "    validation_data=val_inputs,\n",
    "    epochs=EPOCHS,\n",
    "    callbacks=callbacks,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}